from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build

from scrapers.greenhouse import GreenhouseScraper
from matching.matcher import filter_jobs
from matching.filters import USER_PREFERENCES
from sheet_reader import (
    refresh_jobs,
    get_sheet_id,
    SPREADSHEET_ID,
    SHEET_NAME,
    CREDENTIALS_FILE,
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Greenhouse companies (name â†’ slug)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GREENHOUSE_COMPANIES = {
    "Airbnb": "airbnb",
    "Stripe": "stripe",
    "Adyen": "adyen",
    "Pinterest": "pinterest",
    "Squarespace": "squarespace",
    "Vimeo": "vimeo",
    "Warby Parker": "warbyparker",
    "Betterment": "betterment",
    "TripAdvisor": "tripadvisor",
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Auth
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
creds = Credentials.from_service_account_file(
    CREDENTIALS_FILE,
    scopes=["https://www.googleapis.com/auth/spreadsheets"],
)
service = build("sheets", "v4", credentials=creds)

sheet_id = get_sheet_id(service, SPREADSHEET_ID, SHEET_NAME)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Scrape ALL companies
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
all_raw_jobs = []

for company_name, slug in GREENHOUSE_COMPANIES.items():
    try:
        print(f"\nğŸ” Scraping Greenhouse: {company_name}")

        scraper = GreenhouseScraper(slug)
        jobs = scraper.fetch_jobs()

        print(f"  â†’ {len(jobs)} jobs scraped")

        all_raw_jobs.extend(jobs)

    except Exception as e:
        print(f"âš ï¸ Failed to scrape {company_name}: {e}")

print(f"\nğŸ“¦ Total jobs scraped: {len(all_raw_jobs)}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Filter (agent intent layer)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
filtered_jobs = filter_jobs(all_raw_jobs, USER_PREFERENCES)

print(f"ğŸ¯ Jobs after filtering: {len(filtered_jobs)}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ingest into Sheets
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
results = refresh_jobs(
    raw_jobs=filtered_jobs,
    service=service,
    spreadsheet_id=SPREADSHEET_ID,
    sheet_name=SHEET_NAME,
    sheet_id=sheet_id,
)

print("\nâœ… Ingestion complete:")
print(results)
